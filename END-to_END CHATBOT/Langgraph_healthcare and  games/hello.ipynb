{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca583443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langgraph in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (0.4.8)\n",
      "Requirement already satisfied: langchain-community in c:\\program files\\python312\\lib\\site-packages (0.3.11)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-anthropic\n",
      "  Downloading langchain_anthropic-0.3.15-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tavily-python\n",
      "  Downloading tavily_python-0.7.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (1.5.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (1.66.5)\n",
      "Collecting openai\n",
      "  Downloading openai-1.84.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (0.3.56)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (2.0.26)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (0.2.2)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (0.1.66)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (2.10.6)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (3.5.0)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.25 (from langchain-community)\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\program files\\python312\\lib\\site-packages (from langchain-community) (2.0.31)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\program files\\python312\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python312\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\program files\\python312\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\program files\\python312\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\program files\\python312\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\program files\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\program files\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\program files\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\program files\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\program files\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\program files\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.25->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python312\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core>=0.1->langgraph) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\program files\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\program files\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\program files\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\program files\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python312\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.7.4->langgraph) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\program files\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\program files\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Collecting anthropic<1,>=0.52.0 (from langchain-anthropic)\n",
      "  Downloading anthropic-0.52.2-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\program files\\python312\\lib\\site-packages (from anthropic<1,>=0.52.0->langchain-anthropic) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from anthropic<1,>=0.52.0->langchain-anthropic) (0.8.2)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in c:\\program files\\python312\\lib\\site-packages (from tavily-python) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\program files\\python312\\lib\\site-packages (from openai) (4.66.3)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.9.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dazau\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python312\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 2.1/2.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langchain_anthropic-0.3.15-py3-none-any.whl (28 kB)\n",
      "Downloading anthropic-0.52.2-py3-none-any.whl (286 kB)\n",
      "Downloading tavily_python-0.7.3-py3-none-any.whl (15 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.5/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.5 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.5 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading openai-1.84.0-py3-none-any.whl (725 kB)\n",
      "   ---------------------------------------- 0.0/725.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 725.5/725.5 kB 14.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pandas, tavily-python, openai, anthropic, langchain-core, langchain-text-splitters, langchain-anthropic, langchain, langchain-community\n",
      "\n",
      "  Attempting uninstall: pandas\n",
      "\n",
      "    Found existing installation: pandas 1.5.3\n",
      "\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "    Uninstalling pandas-1.5.3:\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "  Attempting uninstall: openai\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "    Found existing installation: openai 1.66.5\n",
      "   ---------------------------------------- 0/9 [pandas]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "    Uninstalling openai-1.66.5:\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "      Successfully uninstalled openai-1.66.5\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   -------- ------------------------------- 2/9 [openai]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "  Attempting uninstall: langchain-core\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "    Found existing installation: langchain-core 0.3.56\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "    Uninstalling langchain-core-0.3.56:\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "      Successfully uninstalled langchain-core-0.3.56\n",
      "   ------------- -------------------------- 3/9 [anthropic]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ----------------- ---------------------- 4/9 [langchain-core]\n",
      "   ---------------------- ----------------- 5/9 [langchain-text-splitters]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ---------------------------------------- 9/9 [langchain-community]\n",
      "\n",
      "Successfully installed anthropic-0.52.2 langchain-0.3.25 langchain-anthropic-0.3.15 langchain-community-0.3.24 langchain-core-0.3.63 langchain-text-splitters-0.3.8 openai-1.84.0 pandas-2.2.3 tavily-python-0.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "litellm 1.60.2 requires tokenizers, which is not installed.\n",
      "langchain-huggingface 0.0.3 requires tokenizers>=0.19.1, which is not installed.\n",
      "embedchain 0.1.127 requires rich<14.0.0,>=13.7.0, but you have rich 14.0.0 which is incompatible.\n",
      "instructor 1.7.7 requires rich<14.0.0,>=13.7.0, but you have rich 14.0.0 which is incompatible.\n",
      "langchain-chroma 0.1.2 requires langchain-core<0.3,>=0.1.40, but you have langchain-core 0.3.63 which is incompatible.\n",
      "pandasai 2.4.2 requires pandas==1.5.3, but you have pandas 2.2.3 which is incompatible.\n",
      "smolagents 1.12.0 requires pillow>=11.0.0, but you have pillow 10.4.0 which is incompatible.\n",
      "streamlit 1.38.0 requires rich<14,>=10.14.0, but you have rich 14.0.0 which is incompatible.\n",
      "streamlit 1.38.0 requires tenacity<9,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
      "camelot-py 1.0.0 requires pdfminer-six>=20240706, but you have pdfminer-six 20231228 which is incompatible.\n",
      "langchain-huggingface 0.0.3 requires langchain-core<0.3,>=0.1.52, but you have langchain-core 0.3.63 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Program Files\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph langchain-community langchain-anthropic tavily-python pandas openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f69d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "db_url = \"https://storage.googleapis.com/benchmarks-artifacts/travel-db/travel2.sqlite\"\n",
    "local_file = \"travel2.sqlite\"\n",
    "# The backup lets us restart for each tutorial section\n",
    "backup_file = \"travel2.backup.sqlite\"\n",
    "overwrite = False\n",
    "if overwrite or not os.path.exists(local_file):\n",
    "    response = requests.get(db_url)\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "    with open(local_file, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    # Backup - we will use this to \"reset\" our DB in each section\n",
    "    shutil.copy(local_file, backup_file)\n",
    "\n",
    "\n",
    "# Convert the flights to present time for our tutorial\n",
    "def update_dates(file):\n",
    "    shutil.copy(backup_file, file)\n",
    "    conn = sqlite3.connect(file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    tables = pd.read_sql(\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table';\", conn\n",
    "    ).name.tolist()\n",
    "    tdf = {}\n",
    "    for t in tables:\n",
    "        tdf[t] = pd.read_sql(f\"SELECT * from {t}\", conn)\n",
    "\n",
    "    example_time = pd.to_datetime(\n",
    "        tdf[\"flights\"][\"actual_departure\"].replace(\"\\\\N\", pd.NaT)\n",
    "    ).max()\n",
    "    current_time = pd.to_datetime(\"now\").tz_localize(example_time.tz)\n",
    "    time_diff = current_time - example_time\n",
    "\n",
    "    tdf[\"bookings\"][\"book_date\"] = (\n",
    "        pd.to_datetime(tdf[\"bookings\"][\"book_date\"].replace(\"\\\\N\", pd.NaT), utc=True)\n",
    "        + time_diff\n",
    "    )\n",
    "\n",
    "    datetime_columns = [\n",
    "        \"scheduled_departure\",\n",
    "        \"scheduled_arrival\",\n",
    "        \"actual_departure\",\n",
    "        \"actual_arrival\",\n",
    "    ]\n",
    "    for column in datetime_columns:\n",
    "        tdf[\"flights\"][column] = (\n",
    "            pd.to_datetime(tdf[\"flights\"][column].replace(\"\\\\N\", pd.NaT)) + time_diff\n",
    "        )\n",
    "\n",
    "    for table_name, df in tdf.items():\n",
    "        df.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "    del df\n",
    "    del tdf\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    return file\n",
    "\n",
    "\n",
    "db = update_dates(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e96c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[1;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://storage.googleapis.com/benchmarks-artifacts/travel-db/swiss_faq.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     11\u001b[0m faq_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://storage.googleapis.com/benchmarks-artifacts/travel-db/swiss_faq.md\"\n",
    ")\n",
    "response.raise_for_status()\n",
    "faq_text = response.text\n",
    "\n",
    "docs = [{\"page_content\": txt} for txt in re.split(r\"(?=\\n##)\", faq_text)]\n",
    "\n",
    "\n",
    "class VectorStoreRetriever:\n",
    "    def __init__(self, docs: list, vectors: list, oai_client):\n",
    "        self._arr = np.array(vectors)\n",
    "        self._docs = docs\n",
    "        self._client = oai_client\n",
    "\n",
    "    @classmethod\n",
    "    def from_docs(cls, docs, oai_client):\n",
    "        embeddings = oai_client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\", input=[doc[\"page_content\"] for doc in docs]\n",
    "        )\n",
    "        vectors = [emb.embedding for emb in embeddings.data]\n",
    "        return cls(docs, vectors, oai_client)\n",
    "\n",
    "    def query(self, query: str, k: int = 5) -> list[dict]:\n",
    "        embed = self._client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\", input=[query]\n",
    "        )\n",
    "        # \"@\" is just a matrix multiplication in python\n",
    "        scores = np.array(embed.data[0].embedding) @ self._arr.T\n",
    "        top_k_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_k_idx_sorted = top_k_idx[np.argsort(-scores[top_k_idx])]\n",
    "        return [\n",
    "            {**self._docs[idx], \"similarity\": scores[idx]} for idx in top_k_idx_sorted\n",
    "        ]\n",
    "\n",
    "\n",
    "retriever = VectorStoreRetriever.from_docs(docs, openai.Client())\n",
    "\n",
    "\n",
    "@tool\n",
    "def lookup_policy(query: str) -> str:\n",
    "    \"\"\"Consult the company policies to check whether certain options are permitted.\n",
    "    Use this before making any flight changes performing other 'write' events.\"\"\"\n",
    "    docs = retriever.query(query, k=2)\n",
    "    return \"\\n\\n\".join([doc[\"page_content\"] for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e70e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947099f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import date, datetime\n",
    "from typing import Optional\n",
    "\n",
    "import pytz\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_user_flight_information(config: RunnableConfig) -> list[dict]:\n",
    "    \"\"\"Fetch all tickets for the user along with corresponding flight information and seat assignments.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries where each dictionary contains the ticket details,\n",
    "        associated flight details, and the seat assignments for each ticket belonging to the user.\n",
    "    \"\"\"\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    passenger_id = configuration.get(\"passenger_id\", None)\n",
    "    if not passenger_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        t.ticket_no, t.book_ref,\n",
    "        f.flight_id, f.flight_no, f.departure_airport, f.arrival_airport, f.scheduled_departure, f.scheduled_arrival,\n",
    "        bp.seat_no, tf.fare_conditions\n",
    "    FROM \n",
    "        tickets t\n",
    "        JOIN ticket_flights tf ON t.ticket_no = tf.ticket_no\n",
    "        JOIN flights f ON tf.flight_id = f.flight_id\n",
    "        JOIN boarding_passes bp ON bp.ticket_no = t.ticket_no AND bp.flight_id = f.flight_id\n",
    "    WHERE \n",
    "        t.passenger_id = ?\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (passenger_id,))\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    results = [dict(zip(column_names, row)) for row in rows]\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_flights(\n",
    "    departure_airport: Optional[str] = None,\n",
    "    arrival_airport: Optional[str] = None,\n",
    "    start_time: Optional[date | datetime] = None,\n",
    "    end_time: Optional[date | datetime] = None,\n",
    "    limit: int = 20,\n",
    ") -> list[dict]:\n",
    "    \"\"\"Search for flights based on departure airport, arrival airport, and departure time range.\"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"SELECT * FROM flights WHERE 1 = 1\"\n",
    "    params = []\n",
    "\n",
    "    if departure_airport:\n",
    "        query += \" AND departure_airport = ?\"\n",
    "        params.append(departure_airport)\n",
    "\n",
    "    if arrival_airport:\n",
    "        query += \" AND arrival_airport = ?\"\n",
    "        params.append(arrival_airport)\n",
    "\n",
    "    if start_time:\n",
    "        query += \" AND scheduled_departure >= ?\"\n",
    "        params.append(start_time)\n",
    "\n",
    "    if end_time:\n",
    "        query += \" AND scheduled_departure <= ?\"\n",
    "        params.append(end_time)\n",
    "    query += \" LIMIT ?\"\n",
    "    params.append(limit)\n",
    "    cursor.execute(query, params)\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    results = [dict(zip(column_names, row)) for row in rows]\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_ticket_to_new_flight(\n",
    "    ticket_no: str, new_flight_id: int, *, config: RunnableConfig\n",
    ") -> str:\n",
    "    \"\"\"Update the user's ticket to a new valid flight.\"\"\"\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    passenger_id = configuration.get(\"passenger_id\", None)\n",
    "    if not passenger_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"SELECT departure_airport, arrival_airport, scheduled_departure FROM flights WHERE flight_id = ?\",\n",
    "        (new_flight_id,),\n",
    "    )\n",
    "    new_flight = cursor.fetchone()\n",
    "    if not new_flight:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return \"Invalid new flight ID provided.\"\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    new_flight_dict = dict(zip(column_names, new_flight))\n",
    "    timezone = pytz.timezone(\"Etc/GMT-3\")\n",
    "    current_time = datetime.now(tz=timezone)\n",
    "    departure_time = datetime.strptime(\n",
    "        new_flight_dict[\"scheduled_departure\"], \"%Y-%m-%d %H:%M:%S.%f%z\"\n",
    "    )\n",
    "    time_until = (departure_time - current_time).total_seconds()\n",
    "    if time_until < (3 * 3600):\n",
    "        return f\"Not permitted to reschedule to a flight that is less than 3 hours from the current time. Selected flight is at {departure_time}.\"\n",
    "\n",
    "    cursor.execute(\n",
    "        \"SELECT flight_id FROM ticket_flights WHERE ticket_no = ?\", (ticket_no,)\n",
    "    )\n",
    "    current_flight = cursor.fetchone()\n",
    "    if not current_flight:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return \"No existing ticket found for the given ticket number.\"\n",
    "\n",
    "    # Check the signed-in user actually has this ticket\n",
    "    cursor.execute(\n",
    "        \"SELECT * FROM tickets WHERE ticket_no = ? AND passenger_id = ?\",\n",
    "        (ticket_no, passenger_id),\n",
    "    )\n",
    "    current_ticket = cursor.fetchone()\n",
    "    if not current_ticket:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return f\"Current signed-in passenger with ID {passenger_id} not the owner of ticket {ticket_no}\"\n",
    "\n",
    "    # In a real application, you'd likely add additional checks here to enforce business logic,\n",
    "    # like \"does the new departure airport match the current ticket\", etc.\n",
    "    # While it's best to try to be *proactive* in 'type-hinting' policies to the LLM\n",
    "    # it's inevitably going to get things wrong, so you **also** need to ensure your\n",
    "    # API enforces valid behavior\n",
    "    cursor.execute(\n",
    "        \"UPDATE ticket_flights SET flight_id = ? WHERE ticket_no = ?\",\n",
    "        (new_flight_id, ticket_no),\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return \"Ticket successfully updated to new flight.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def cancel_ticket(ticket_no: str, *, config: RunnableConfig) -> str:\n",
    "    \"\"\"Cancel the user's ticket and remove it from the database.\"\"\"\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    passenger_id = configuration.get(\"passenger_id\", None)\n",
    "    if not passenger_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"SELECT flight_id FROM ticket_flights WHERE ticket_no = ?\", (ticket_no,)\n",
    "    )\n",
    "    existing_ticket = cursor.fetchone()\n",
    "    if not existing_ticket:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return \"No existing ticket found for the given ticket number.\"\n",
    "\n",
    "    # Check the signed-in user actually has this ticket\n",
    "    cursor.execute(\n",
    "        \"SELECT ticket_no FROM tickets WHERE ticket_no = ? AND passenger_id = ?\",\n",
    "        (ticket_no, passenger_id),\n",
    "    )\n",
    "    current_ticket = cursor.fetchone()\n",
    "    if not current_ticket:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return f\"Current signed-in passenger with ID {passenger_id} not the owner of ticket {ticket_no}\"\n",
    "\n",
    "    cursor.execute(\"DELETE FROM ticket_flights WHERE ticket_no = ?\", (ticket_no,))\n",
    "    conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return \"Ticket successfully cancelled.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
